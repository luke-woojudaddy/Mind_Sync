import os
import json
import random
import numpy as np
import requests
from PIL import Image
from io import BytesIO
import traceback
import torch
from transformers import CLIPProcessor, CLIPModel

# ==========================================
# [ì„¤ì •] AI ì—”ì§„ ì„¤ì •
# ==========================================
CACHE_FILE = "ai_cache_v2.npz"
MODEL_NAME = 'clip-ViT-B-32-multilingual-v1'

class AIEngine:
    def __init__(self, card_list_file, static_cards_path, word_pool, external_image_url):
        self.is_ready = False
        self.model = None
        self.word_embeddings = {}
        self.card_embeddings = {}
        self.card_list_file = card_list_file
        self.static_cards_path = static_cards_path
        # [I18n] Extract Korean words for embedding generation if input is list of dicts
        self.word_pool = [w['ko'] if isinstance(w, dict) else w for w in word_pool]
        self.external_image_url = external_image_url
        
        print("ğŸ¤– [AI Engine] Initializing...")
        try:
            from sentence_transformers import SentenceTransformer
            from transformers import CLIPProcessor, CLIPModel
            import torch

            print(f"ğŸ“¥ [AI Engine] Loading Text model '{MODEL_NAME}'...")
            self.text_model = SentenceTransformer(MODEL_NAME)
            
            print(f"ğŸ“¥ [AI Engine] Loading Image model 'openai/clip-vit-base-patch32' via Transformers...")
            self.image_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
            self.image_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            
            self.is_ready = True
            print("âœ… [AI Engine] Models loaded successfully.")
            
            self._load_or_generate_cache()
            
        except Exception as e:
            print(f"âš ï¸ [AI Engine] Failed to load AI model. Falling back to Random Mode.")
            print(f"   Error: {e}")
            traceback.print_exc()
            self.is_ready = False

    def _load_or_generate_cache(self):
        """ìºì‹œë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.is_ready: return

        # ì¹´ë“œ ëª©ë¡ ë¡œë“œ
        all_cards = []
        if os.path.exists(self.card_list_file):
            with open(self.card_list_file, 'r', encoding='utf-8') as f:
                all_cards = json.load(f)
        else:
            if os.path.exists(self.static_cards_path):
                all_cards = [f for f in os.listdir(self.static_cards_path) 
                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        # ìºì‹œ í™•ì¸
        cache_path = os.path.join(os.path.dirname(__file__), CACHE_FILE)
        cache_valid = False
        
        if os.path.exists(cache_path):
            try:
                print(f"ğŸ“‚ [AI Engine] Loading cache from {CACHE_FILE}...")
                data = np.load(cache_path, allow_pickle=True)
                cached_words = data['words']
                cached_cards = data['cards']
                self.word_embeddings = data['word_embeddings'].item()
                self.card_embeddings = data['card_embeddings'].item()
                
                # ë°ì´í„° ë³€ê²½ í™•ì¸ (ê°„ë‹¨í•˜ê²Œ ê°œìˆ˜ì™€ ì²«/ë§ˆì§€ë§‰ ì•„ì´í…œìœ¼ë¡œ ë¹„êµ)
                if (set(cached_words) == set(self.word_pool)) and (set(cached_cards) == set(all_cards)):
                    print("âœ… [AI Engine] Cache is up to date.")
                    cache_valid = True
                else:
                    print("ğŸ”„ [AI Engine] Data changed. Rebuilding cache...")
            except Exception as e:
                print(f"âš ï¸ [AI Engine] Cache corrupted. Rebuilding... ({e})")

        if not cache_valid:
            print("âš™ï¸ [AI Engine] Generating embeddings... (This may take a few minutes)")
            self._generate_embeddings(all_cards)
            
            # ìºì‹œ ì €ì¥
            print(f"ğŸ’¾ [AI Engine] Saving cache to {CACHE_FILE}...")
            np.savez_compressed(
                cache_path, 
                words=self.word_pool, 
                cards=all_cards, 
                word_embeddings=self.word_embeddings, 
                card_embeddings=self.card_embeddings
            )
            print("âœ… [AI Engine] Cache saved.")

    def _generate_embeddings(self, all_cards):
        """ë‹¨ì–´ì™€ ì´ë¯¸ì§€ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # 1. ë‹¨ì–´ ì„ë² ë”©
        print(f"   Running text embeddings for {len(self.word_pool)} words...")
        word_vecs = self.text_model.encode(self.word_pool)
        for i, word in enumerate(self.word_pool):
            self.word_embeddings[word] = word_vecs[i]
            
        # 2. ì´ë¯¸ì§€ ì„ë² ë”©
        print(f"   Running image embeddings for {len(all_cards)} cards...")
        processed_count = 0
        
        # ì´ë¯¸ì§€ ë¡œë”© í—¬í¼
        def load_image(card_id):
            # 1) ë¡œì»¬ ì‹œë„
            local_path = os.path.join(self.static_cards_path, card_id)
            if os.path.exists(local_path):
                return Image.open(local_path)
            
            # 2) ì™¸ë¶€ URL ì‹œë„ (Git Pages ë“±)
            if self.external_image_url:
                url = f"{self.external_image_url}/{card_id}"
                try:
                    response = requests.get(url, timeout=5)
                    response.raise_for_status()
                    return Image.open(BytesIO(response.content))
                except:
                    pass
            return None

        # ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ì‹  ê°„ë‹¨íˆ ìˆœì°¨ ì²˜ë¦¬ (ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°œë³„ ê±´ë„ˆë›°ê¸° ìœ„í•¨)
        # ì†ë„ë¥¼ ìœ„í•´ì„  ë°°ì¹˜ê°€ ì¢‹ì§€ë§Œ, ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë•Œë¬¸ì— ê°œë³„ ì²˜ë¦¬
        for i, card_id in enumerate(all_cards):
            try:
                img = load_image(card_id)
                if img:
                    # [Fix] WebP í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°: ìˆœìˆ˜ RGB ì´ë¯¸ì§€ë¡œ ì¬ìƒì„±
                    rgb_img = Image.new("RGB", img.size)
                    rgb_img.paste(img, (0, 0))
                    
                    inputs = self.image_processor(images=rgb_img, return_tensors="pt")
                    with torch.no_grad():
                         vec = self.image_model.get_image_features(**inputs)[0].cpu().numpy().flatten()
                    # [Fix] í™•ì¥ì ì œê±°í•˜ì—¬ í‚¤ ì €ì¥ (.webp vs .png ë¶ˆì¼ì¹˜ í•´ê²°)
                    key = os.path.splitext(card_id)[0]
                    self.card_embeddings[key] = vec
                    processed_count += 1
                else:
                    print(f"   âš ï¸ Image not found: {card_id}")
            except Exception as e:
                print(f"   âš ï¸ Error processing {card_id}: {e}")
                traceback.print_exc()
            
            if (i + 1) % 10 == 0:
                print(f"   ... Processed {i + 1}/{len(all_cards)} images")

        print(f"âœ… [AI Engine] Embeddings generated. (Words: {len(self.word_embeddings)}, Cards: {processed_count})")

    def _cosine_similarity(self, vec1, vec2):
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        if norm1 == 0 or norm2 == 0: return 0.0
        return np.dot(vec1, vec2) / (norm1 * norm2)

    # --- Public Methods ---

    def analyze_storyteller_candidates(self, card_id, candidates):
        """
        [Smart Reroll Logic]
        ë‹¨ìˆœíˆ ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë‹¨ì–´ë¥¼ ë½‘ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,
        ê²Œì„ì˜ ì¬ë¯¸ë¥¼ ìœ„í•´ 'ì ë‹¹íˆ ëª¨í˜¸í•œ(Sweet Spot)' ë‹¨ì–´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        
        Returns:
            (selected_word, should_reroll)
        """
        # [Fix] í™•ì¥ì ì œê±°í•˜ì—¬ í‚¤ ì¡°íšŒ
        key = os.path.splitext(card_id)[0]
        if not self.is_ready or key not in self.card_embeddings:
            print(f"âš ï¸ [AI Storyteller] Embedding not found for {card_id} (Key: {key})")
            return random.choice(candidates), False

        try:
            card_vec = self.card_embeddings[key]
            scores = []
            
            for word in candidates:
                # [I18n] word comes as dict {'ko':..., 'en':...} or string
                word_text = word['ko'] if isinstance(word, dict) else word
                
                if word_text in self.word_embeddings:
                    sim = self._cosine_similarity(card_vec, self.word_embeddings[word_text])
                    scores.append((word, sim)) # Return original object
            
            scores.sort(key=lambda x: x[1], reverse=True)
            
            # --- ì „ëµ 1: Sweet Spot (0.4 ~ 0.7) ì°¾ê¸° ---
            # ë„ˆë¬´ ë»”í•˜ì§€ë„(>0.8), ë„ˆë¬´ ëœ¬ê¸ˆì—†ì§€ë„(<0.3) ì•Šì€ êµ¬ê°„
            sweet_spots = [item for item in scores if 0.4 <= item[1] <= 0.7]
            
            if sweet_spots:
                # ì ì ˆí•œ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ê·¸ ì¤‘ì—ì„œ ëœë¤ ì„ íƒ
                selected = random.choice(sweet_spots)
                # selected[0] is the word object/string
                word_log = selected[0]['ko'] if isinstance(selected[0], dict) else selected[0]
                print(f"ğŸ§  [AI Storyteller] Found Sweet Spot! Card: {card_id} -> {word_log} ({selected[1]:.2f})")
                return selected[0], False
            
            # --- ì „ëµ 2: Sweet Spotì´ ì—†ë‹¤ë©´? ---
            # ë§Œì•½ ëª¨ë“  ë‹¨ì–´ê°€ ë„ˆë¬´ ë»”í•˜ê±°ë‚˜(>0.8) ë„ˆë¬´ ê´€ë ¨ì—†ë‹¤ë©´(<0.3) -> ë¦¬ë¡¤ ì¶”ì²œ
            # ë‹¤ë§Œ, ìƒìœ„ê¶Œ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´(<0.3) ë¬´ì¡°ê±´ ë¦¬ë¡¤
            top_score = scores[0][1] if scores else 0
            if top_score < 0.35:
                print(f"ğŸ§  [AI Storyteller] Scores too low (Top: {top_score:.2f}). Suggest Reroll.")
                return None, True
            
            if top_score > 0.85:
                 print(f"ğŸ§  [AI Storyteller] Scores too obvious (Top: {top_score:.2f}). Suggest Reroll.")
                 return None, True

            # ë¦¬ë¡¤ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•Šì§€ë§Œ Sweet Spotë„ ì•„ë‹Œ ì• ë§¤í•œ ê²½ìš° -> ê·¸ëƒ¥ Top Pick ì‚¬ìš©
            # (ê³„ì† ë¦¬ë¡¤í•  ìˆœ ì—†ìœ¼ë¯€ë¡œ)
            word_log = scores[0][0]['ko'] if isinstance(scores[0][0], dict) else scores[0][0]
            print(f"ğŸ§  [AI Storyteller] No Sweet Spot, but usable. Pick Top 1: {word_log}")
            return scores[0][0], False
            
        except Exception as e:
            print(f"âš ï¸ [AI Error] analyze_storyteller_candidates: {e}")
            return random.choice(candidates), False

    def get_best_card(self, word, card_hand_list):
        """[ì œì¶œ ë‹¨ê³„] ì œì‹œì–´ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ì¹´ë“œë¥¼ ë‚´ ì†ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤."""
        if not self.is_ready or word not in self.word_embeddings:
            return random.choice(card_hand_list)['id']

        try:
            word_vec = self.word_embeddings[word]
            scores = []
            
            for card in card_hand_list:
                card_id_orig = card['id']
                # [Fix] í™•ì¥ì ì œê±°
                key = os.path.splitext(card_id_orig)[0]
                
                if key in self.card_embeddings:
                    sim = self._cosine_similarity(self.card_embeddings[key], word_vec)
                    scores.append((card_id_orig, sim))
                else:
                    scores.append((card_id_orig, -1.0)) # ì„ë² ë”© ì—†ìœ¼ë©´ ìµœí•˜ì 
            
            scores.sort(key=lambda x: x[1], reverse=True)
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ ì„ íƒ
            best_card = scores[0][0]
            print(f"ğŸ§  [AI Submit] Word: '{word}' -> Hand Scores: {[f'{c[:5]}..({s:.2f})' for c, s in scores[:3]]} -> Picked: {best_card}")
            return best_card

        except Exception as e:
            print(f"âš ï¸ [AI Error] get_best_card: {e}")
            return random.choice(card_hand_list)['id']

    def get_voted_card(self, word, voting_candidates, my_card_id=None):
        """[íˆ¬í‘œ ë‹¨ê³„] ì œì‹œì–´ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ì¹´ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤ (ë³¸ì¸ ì¹´ë“œ ì œì™¸)"""
        # voting_candidates: [{'user_id':..., 'card_id':...}, ...]
        if not self.is_ready or word not in self.word_embeddings:
             # ëœë¤ ì„ íƒ (ë³¸ì¸ ì¹´ë“œ ì œì™¸)
            valid = [c for c in voting_candidates if c['card_id'] != my_card_id]
            if not valid: return None
            return random.choice(valid)['card_id']

        try:
            word_vec = self.word_embeddings[word]
            scores = []
            
            for candidate in voting_candidates:
                c_id = candidate['card_id']
                if c_id == my_card_id: continue # ë‚´ ì¹´ë“œëŠ” íˆ¬í‘œ ë¶ˆê°€ (ì´ë¯¸ í•„í„°ë§ ë˜ì–´ ì˜¤ê² ì§€ë§Œ ì•ˆì „ì¥ì¹˜)
                
                # [Fix] í™•ì¥ì ì œê±°
                key = os.path.splitext(c_id)[0]
                if key in self.card_embeddings:
                    sim = self._cosine_similarity(self.card_embeddings[key], word_vec)
                    scores.append((c_id, sim, candidate['user_id']))
                else:
                    scores.append((c_id, -1.0, candidate['user_id']))

            scores.sort(key=lambda x: x[1], reverse=True)
            
            if not scores: return None
            
            # íˆ¬í‘œëŠ” ì •ë‹µì„ ë§ì¶°ì•¼ í•˜ë¯€ë¡œ Top 1 ì„ íƒ
            best_choice = scores[0][0]
            print(f"ğŸ§  [AI Vote] Word: '{word}' -> Vote Scores: {[f'{c[:5]}..({s:.2f})' for c, s, u in scores[:3]]} -> Voted: {best_choice}")
            return best_choice
            
        except Exception as e:
            print(f"âš ï¸ [AI Error] get_voted_card: {e}")
            valid = [c for c in voting_candidates if c['card_id'] != my_card_id]
            return random.choice(valid)['card_id'] if valid else None
